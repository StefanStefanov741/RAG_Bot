{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f455a48b-cf2b-4ac4-a56d-267a8ae4a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%xmode verbose\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import layoutparser as lp\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "#For Detectron2\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import layoutparser as lp\n",
    "\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "path= ''\n",
    "prediction_score_threshold = 0.7\n",
    "class_labels = ['text', 'title', 'list', 'table', 'figure']\n",
    "\n",
    "# Set up Detectron2 config\n",
    "cfg = get_cfg()\n",
    "#The following line can be used instead of the one after it, however it causes warnings. (Find out why?)\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a threshold for predictions\n",
    "cfg.MODEL.WEIGHTS = path+ \"model_final.pth\" \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = prediction_score_threshold\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
    "\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6555d10d-114e-4356-a0b6-250662310478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_image(path):\n",
    "    \"\"\"\n",
    "    Converts a PDF Document into a list of images     \n",
    "    Args:\n",
    "    pdf_path (String): Path to the pdf file for information extraction.\n",
    "\n",
    "    Returns:\n",
    "    A list of images (each page is an image) in the format [[1,image1],[2,image2]]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Convert PDF to images\n",
    "    images = convert_from_path(path)\n",
    "    return enumerate(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ea1d68-efc4-4649-84d2-7827ed3cf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_elements_detectron(pdf_path, display= False) :\n",
    "    \"\"\"\n",
    "    Extracts elements from a pdf file by utilizing detectron2\n",
    "    \n",
    "    Args:\n",
    "    pdf_path (String): Path to the pdf file for information extraction.\n",
    "    \n",
    "    Returns:\n",
    "    An array of extracted texts\n",
    "    \"\"\"\n",
    "    \n",
    "    path= ''\n",
    "    prediction_score_threshold = 0.7\n",
    "    class_labels = ['text', 'title', 'list', 'table', 'figure']\n",
    "\n",
    "    # Set up Detectron2 config\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a threshold for predictions\n",
    "    cfg.MODEL.WEIGHTS = path+ \"model_final.pth\" # e.g., PubLayNet pre-trained model\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = prediction_score_threshold\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
    "\n",
    "    cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "    # Initialize the OCR library (ensure tesseract is installed and in PATH)\n",
    "    #pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'  # Update if necessary\n",
    "\n",
    "    # Initialize an empty list to store the content of each detected object\n",
    "    detected_texts = []\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    images= pdf_to_image(pdf_path)\n",
    "    for i, current_image in images:\n",
    "        #img = np.array(Image.open(current_image))\n",
    "        img = np.array(current_image)\n",
    "\n",
    "        # Perform page object detection\n",
    "        outputs = predictor(img)\n",
    "\n",
    "        # Debug outputs\n",
    "        instances = outputs[\"instances\"].to(\"cpu\")\n",
    "        pred_boxes = instances.pred_boxes\n",
    "        scores = instances.scores\n",
    "        pred_classes = instances.pred_classes\n",
    "\n",
    "        # Loop through each detected object\n",
    "        for i in range(0, len(pred_boxes)):\n",
    "            box = pred_boxes[i].tensor.numpy()[0]\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "\n",
    "            # Crop the image to the bounding box\n",
    "            cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Perform OCR on the cropped image\n",
    "            text = pytesseract.image_to_string(cropped_img, output_type=Output.STRING)\n",
    "\n",
    "            # Append the extracted text to the list\n",
    "\n",
    "            label_key = int(pred_classes[i].numpy())\n",
    "            label = class_labels[label_key]\n",
    "            detected_texts.append([label,text.strip()])  # Store each text as a single-element list\n",
    "\n",
    "\n",
    "            #print(f\"Detected {label}: {text.strip()}\")\n",
    "\n",
    "        if display:\n",
    "\n",
    "            for i in range(0, len(pred_boxes)):\n",
    "                box = pred_boxes[i].tensor.numpy()[0]\n",
    "                score = round(float(scores[i].numpy()), 4)\n",
    "                label_key = int(pred_classes[i].numpy())\n",
    "                label = class_labels[label_key]\n",
    "                x = int(box[0])\n",
    "                y = int(box[1])\n",
    "                w = int(box[2] - box[0])\n",
    "                h = int(box[3] - box[1])\n",
    "\n",
    "                print('Detected object of label=' + str(label) + ' with score=' + str(score) + ' and in box={x=' + str(x) + ', y=' + str(y) + ', w=' + str(w) + ', h=' + str(h) + '}')\n",
    "            # Draw the bounding boxes\n",
    "            for i in range(len(pred_boxes)):\n",
    "                box = pred_boxes[i].tensor.numpy()[0]\n",
    "                score = round(float(scores[i].numpy()), 4)\n",
    "                label_key = int(pred_classes[i].numpy())\n",
    "                label = class_labels[label_key]\n",
    "\n",
    "                x = int(box[0])\n",
    "                y = int(box[1])\n",
    "                w = int(box[2] - box[0])\n",
    "                h = int(box[3] - box[1])\n",
    "\n",
    "                # Draw the rectangle around each object\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "                # Put label and score text above the bounding box\n",
    "                cv2.putText(img, f\"{label}: {score}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Convert the image from BGR to RGB (for matplotlib display)\n",
    "            image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Display the image with bounding boxes\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image_rgb)\n",
    "            plt.axis(\"off\")  # Hide the axis\n",
    "            plt.show()\n",
    "    \n",
    "    return detected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef2cf37-6472-41da-918d-e7cc7a4e8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path= path+'biology_paper.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbac36-f24b-4524-82ce-d50d4ebb0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "%xmode verbose\n",
    "\n",
    "pdf_to_elements_detectron(pdf_path, display= False) #Change display to true to vizualize the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bcc779-e353-47ac-b40b-344c0e87c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "def pdf_to_elements_yolox(pdf_path) :\n",
    "    \"\"\"\n",
    "    Extracts elements from a pdf file by utilizing yolox without the need of an API\n",
    "    \n",
    "    Args:\n",
    "    pdf_path (String): Path to the pdf file for information extraction.\n",
    "    \n",
    "    Returns:\n",
    "    A list of Unstructured Elements\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        elements = partition(filename=pdf_path,strategy='hi_res',skip_infer_table_types=[])\n",
    "        i = -1\n",
    "        for el in elements:\n",
    "            i+=1\n",
    "            if(el.category =='Table'):\n",
    "                elements[i].text=elements[i].metadata.text_as_html\n",
    "            if(el.category =='Header'):\n",
    "                elements[i].category=\"Title\"\n",
    "        return  elements\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be8bf4-b104-4d48-a624-c8bfbd43056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "from unstructured.documents.elements import Element\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "from pdfminer.layout import LTTextBoxHorizontal\n",
    "from unstructured.documents.elements import Element, ElementMetadata, CoordinateSystem\n",
    "\n",
    "def _extract_text_with_layout(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text and layout information from a PDF, capturing text along with its position and font size.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file for extracting text and layout information.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict[str, Any]]: A list of dictionaries where each dictionary contains text, bounding box (bbox), and font size of the text element.\n",
    "    \"\"\"\n",
    "    text_with_layout = []\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                for text_line in element:\n",
    "                    text_with_layout.append({\n",
    "                        'text': text_line.get_text(),\n",
    "                        'bbox': text_line.bbox,  # (x0, y0, x1, y1)\n",
    "                        'font_size': text_line._objs[0].size if text_line._objs else None\n",
    "                    })\n",
    "    return text_with_layout\n",
    "\n",
    "def _detect_titles(text_with_layout, title_font_size_threshold=14):\n",
    "    \"\"\"\n",
    "    Detects potential titles in the extracted text based on font size and positioning.\n",
    "\n",
    "    Args:\n",
    "    text_with_layout (List[Dict[str, Any]]): List of text elements with layout information (text, bbox, font size).\n",
    "    title_font_size_threshold (int, optional): The minimum font size considered to identify a title. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict[str, Any]]: A list of dictionaries containing title text, bounding box, and font size.\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    for item in text_with_layout:\n",
    "        text = item['text'].strip()\n",
    "        if text:\n",
    "            font_size = item['font_size']\n",
    "            if font_size and font_size >= title_font_size_threshold:\n",
    "                titles.append({\n",
    "                    'text': text,\n",
    "                    'bbox': item['bbox'],\n",
    "                    'font_size': font_size\n",
    "                })\n",
    "    return titles\n",
    "\n",
    "def _is_string_in_titles(search_string: str, titles: List[Dict[str, Any]]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a specific string is present in the list of detected titles.\n",
    "\n",
    "    Args:\n",
    "    search_string (str): The string to search for within the titles.\n",
    "    titles (List[Dict[str, Any]]): List of title elements (text, bbox, font size) identified by `_detect_titles`.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the search string is found within any of the titles, otherwise False.\n",
    "    \"\"\"\n",
    "    search_string = search_string.lower()\n",
    "    for title in titles:\n",
    "        if search_string in title['text'].lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def pdf_to_elements_pdfminer(file_path: str) -> List[Element]:\n",
    "    \"\"\"\n",
    "    Extracts text elements from a PDF and returns them as a list of `Element` instances, \n",
    "    with metadata such as coordinates, page number, and distinguishing between titles and narrative text.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    List[Unstructured Element]: A list of `Element` objects representing the text elements in the PDF, with associated metadata such as coordinates and category (title or narrative text).\n",
    "    \"\"\"\n",
    "    extracted_elements = []\n",
    "\n",
    "    titles = _detect_titles(_extract_text_with_layout(file_path))\n",
    "    \n",
    "    try:\n",
    "        for page_number, page_layout in enumerate(extract_pages(file_path), start=1):\n",
    "            for page_element in page_layout:\n",
    "                if isinstance(page_element, LTTextContainer):\n",
    "                    text = page_element.get_text().strip()\n",
    "                    if text:\n",
    "                        x0, y0, x1, y1 = page_element.bbox\n",
    "                        element_type = \"Title\" if _is_string_in_titles(search_string=text, titles=titles) else \"'NarrativeText'\"\n",
    "                        \n",
    "                        coordinate_system = CoordinateSystem(\n",
    "                            width=x1 - x0,\n",
    "                            height=y1 - y0\n",
    "                        )\n",
    "                        \n",
    "                        metadata = ElementMetadata(\n",
    "                            filename=file_path,\n",
    "                            page_number=page_number,\n",
    "                            coordinates=coordinate_system,\n",
    "                            languages=['en']\n",
    "                        )\n",
    "                        \n",
    "                        unstructured_element = Element(\n",
    "                            element_id=None,\n",
    "                            coordinates=((x0, y0), (x1, y1)),\n",
    "                            coordinate_system=coordinate_system,\n",
    "                            metadata=metadata,\n",
    "                            detection_origin=element_type\n",
    "                        )\n",
    "\n",
    "                        unstructured_element.category = element_type\n",
    "                        unstructured_element.text = text\n",
    "                        extracted_elements.append(unstructured_element)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "    return extracted_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd6efc-c7b1-4c96-be73-45296418c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_elements = pdf_to_elements_yolox(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95870ce4-5a9d-41bd-aec9-6e666a3fd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_elements[0].category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68127f73-1dd5-4a2e-95e3-eaab4bef8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_elements[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5d42e-a65f-4690-9b61-0205fb82d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = pdf_to_elements_pdfminer(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557e062-b866-41c5-a63f-40bcc1bb1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[0].category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357677c-a485-4982-9370-6b6e712c8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[0].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
